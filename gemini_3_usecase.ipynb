{
  "cells": [
    {
      "cell_type": "code",
      "id": "mZugDLAcQGcWLB1kcQZbs0jd",
      "metadata": {
        "tags": [],
        "id": "mZugDLAcQGcWLB1kcQZbs0jd"
      },
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Google Gen AI SDK for Python\n",
        "\n",
        "Gemini 3 API features require Gen AI SDK for Python version 1.51.0 or later."
      ],
      "metadata": {
        "id": "6zBIlvW3hOpj"
      },
      "id": "6zBIlvW3hOpj"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkIsnlTVhPZz",
        "outputId": "02a2c5aa-dc21-4c4c-8a2a-3bf408e5dea7"
      },
      "id": "AkIsnlTVhPZz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-pubsub 2.27.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.47.0 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "Jowdui5GhRvD"
      },
      "id": "Jowdui5GhRvD"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from IPython.display import HTML, Markdown, display\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel"
      ],
      "metadata": {
        "id": "vi7zqRu9hVUs"
      },
      "id": "vi7zqRu9hVUs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your Google Cloud Project for Vertex AI\n",
        "\n",
        "You can use a Google Cloud Project or an API Key for authentication. This notebook uses a Google Cloud Project.\n",
        "\n",
        "- [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)"
      ],
      "metadata": {
        "id": "M30ERP2shX0s"
      },
      "id": "M30ERP2shX0s"
    },
    {
      "cell_type": "code",
      "source": [
        "# fmt: off\n",
        "PROJECT_ID = \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "# fmt: on\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"global\"\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "Cz0kKN4qhfJ7"
      },
      "id": "Cz0kKN4qhfJ7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose a Gemini 3 Pro model\n",
        "\n",
        "Use `gemini-3-pro-preview` in this tutorial. Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ],
      "metadata": {
        "id": "UW9NjJ91hhi6"
      },
      "id": "UW9NjJ91hhi6"
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-3-pro-preview\"  # @param [\"gemini-3-pro-preview\"] {type: \"string\"}"
      ],
      "metadata": {
        "id": "qhj6XkKQhkli"
      },
      "id": "qhj6XkKQhkli",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Act as a Strategic Assistant. Analyze this handwritten daily plan\n",
        "\n",
        "1. Morning Briefing & Status Update: Identify the core objective and current\n",
        "   status based on visual cues (e.g., icons, emphasis markers).\n",
        "2. The Priority Stack:: List fixed time blocks, identifying any hard\n",
        "   deadlines and tentative placeholders.\n",
        "3. Productivity Guardrails: Identify and interpret  Global\n",
        "   Execution Rules or time boundaries.\n",
        "4. Real-time Interventions: Identify unplanned disruptions or incoming queries\n",
        "    and assess their impact on the schedule.\n",
        "5. Actionable Triggers: Map symbols (?, !!, ⚠) to specific tasks that\n",
        "   require external data or represent critical risks.\n",
        "\n",
        "Output the result as a 'Strategic Daily Briefing' that is concise and\n",
        "action-oriented. Make sure you have covered all the points\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z70joJeehsaT"
      },
      "id": "Z70joJeehsaT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✅ Note\n",
        "\n",
        "- If your content is stored in [Google Cloud Storage](https://cloud.google.com/storage), you can use the `from_uri`  method to create a `Part` object.\n",
        "- If your content is stored in your local file system, you can read it in as bytes data and use the `from_bytes` method to create a `Part` object.\n",
        "\n",
        "\n",
        "```\n",
        "# Download and open an image locally.\n",
        "! wget https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\n",
        "\n",
        "with open(\"meal.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
        "        \"Write a short and engaging blog post based on this picture.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "X0fyXsu378B6"
      },
      "id": "X0fyXsu378B6"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=1.0,\n",
        "        top_p=0.9,\n",
        "        max_output_tokens=8000,\n",
        "        seed=42\n",
        "    ),\n",
        "    contents=[\n",
        "        types.Part(\n",
        "            file_data=types.FileData(\n",
        "                file_uri=\"gs://ai_camp_demo_artefacts/tasklist_1.jpg\",\n",
        "                mime_type=\"image/jpeg\",\n",
        "            ),\n",
        "            media_resolution=types.PartMediaResolution(\n",
        "                level=types.PartMediaResolutionLevel.MEDIA_RESOLUTION_HIGH,\n",
        "            ),\n",
        "        ),\n",
        "        prompt\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "1YYN-Kj4h3s3",
        "outputId": "c3cfd574-cd7b-4ab5-be8f-d3b1f0f4ae4d"
      },
      "id": "1YYN-Kj4h3s3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the handwritten analysis of the daily plan for Wednesday 01/14, here is your **Strategic Daily Briefing**.\n\n### 1. Morning Briefing & Status Update\n*   **Core Objective:** Execute the **2:00 PM Design Review**. This is the anchor event of the day; success depends entirely on completing the presentation deck.\n*   **Current Status:** **CRITICAL / AT RISK**. The visual marker **\"⚠ running behind\"** combined with **\"Finish slides !!!\"** indicates immediate schedule compression. The note \"push non-urgent?\" suggests you are already in triage mode.\n\n### 2. The Priority Stack\n**Fixed Time Blocks:**\n*   **09:30 – 10:00:** Standup\n*   **11:00 – 11:30:** 1:1 Meeting\n*   **14:00 – 15:00:** **Design Review (High Stakes)**\n\n**Hard Deadlines:**\n*   **13:30:** Slides must be finished (30-minute buffer before review).\n*   **EOD:** Reply to John Doe regarding metrics.\n\n**Tentative/Placeholders:**\n*   **16:30:** Catch-up (Marked \"Tentative\" & Circled).\n*   **Gym:** (Marked with \"?\") – Likely to be cut given the schedule compression.\n\n### 3. Productivity Guardrails\n*   **Deep Work Mandate:** You explicitly noted a need for a **\"30 min deep focus block\"** to improve morning focus. *Recommendation: Schedule this immediately between 11:30 and 13:30 to finish slides.*\n*   **Boundary Conflict:** You set a rule for **\"no meetings after 4 pm\"**, yet have a tentative **4:30 Catch-up**. *Action: Cancel or reschedule the 4:30 to honor the boundary.*\n*   **Prerequisite:** **\"COFFEE FIRST\"** (Non-negotiable activation step).\n\n### 4. Real-time Interventions\nTwo unplanned disruptions have entered the workflow (scribbled in colored ink) that threaten your slide deadline:\n*   **Red Ink (High Risk):** \"Product team asking for quick input?\" -> *Strategy: Defer response until after 2 PM.*\n*   **Blue Ink (Medium Risk):** \"Customer question came in?\" -> *Strategy: Route to \"Email backlog\" slot; do not process now.*\n\n### 5. Actionable Triggers\n*   **!!! (Slides):** **Immediate Action Required.** Abandon \"Email backlog\" tasks until slides are complete.\n*   **? (John Doe/Metrics):** **Data Gap.** You cannot reply to John without the metrics. *Action: Ping data source immediately so numbers are ready for your EOD reply.*\n*   **⚠ (Running Behind):** **Contingency Trigger.** Execute your note to \"push non-urgent.\"\n*   **Boxed (CALL MOM):** **Personal Priority.** High visibility marker suggests this cannot slip to tomorrow despite work stress.\n*   **Jane Note:** \"Remember to ask Jane about timelines.\" *Action: Add to 9:30 Standup agenda.*"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_generation = client.models.generate_content(\n",
        "    model=\"gemini-3-pro-image-preview\",\n",
        "    contents=f\"\"\"\n",
        "    Generate an infographic of the daily schedule: {response.text}.\n",
        "    Stick to the facts and do not miss any steps\n",
        "    \"\"\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        image_config=types.ImageConfig(\n",
        "            aspect_ratio=\"16:9\",\n",
        "            image_size=\"4K\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "image_parts = [part for part in image_generation.parts if part.inline_data]\n",
        "\n",
        "if image_parts:\n",
        "    image = image_parts[0].as_image()\n",
        "    image.save('infographic_schedule_1.png')\n",
        "    image.show()"
      ],
      "metadata": {
        "id": "OReOWaWtiC-S"
      },
      "id": "OReOWaWtiC-S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take Home Task\n",
        "What if you use low resolution?\n",
        "What variation do you see in the response?"
      ],
      "metadata": {
        "id": "PDIoe8yUiOo6"
      },
      "id": "PDIoe8yUiOo6"
    },
    {
      "cell_type": "code",
      "source": [
        "# response = client.models.generate_content(\n",
        "#     model=MODEL_ID,\n",
        "#     contents=[\n",
        "#         types.Part(\n",
        "#             file_data=types.FileData(\n",
        "#                 file_uri=\"gs://ai_camp_demo_artefacts/tasklist.jpg\",\n",
        "#                 mime_type=\"image/jpeg\",\n",
        "#             ),\n",
        "#             media_resolution=types.PartMediaResolution(\n",
        "#                 level=types.PartMediaResolutionLevel.MEDIA_RESOLUTION_LOW\n",
        "#             ),\n",
        "#         ),\n",
        "#         prompt\n",
        "#     ],\n",
        "# )\n",
        "\n",
        "# display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "vudc5_HXiLyF"
      },
      "id": "vudc5_HXiLyF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = \"\"\"\n",
        "Look at the red-ink interruption and the 'Customer Questions' note. Based on the 1:30 PM slide deadline,\n",
        "what is the latest possible time I can address these without missing my 2:00 PM review?\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qm3m2JzJiePZ"
      },
      "id": "qm3m2JzJiePZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reasoning_response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Part(\n",
        "            file_data=types.FileData(\n",
        "                file_uri=\"gs://ai_camp_demo_artefacts/tasklist_1.jpg\",\n",
        "                mime_type=\"image/jpeg\",\n",
        "            ),\n",
        "            media_resolution=types.PartMediaResolution(\n",
        "                level=types.PartMediaResolutionLevel.MEDIA_RESOLUTION_HIGH\n",
        "            ),\n",
        "        ),\n",
        "        prompt_1\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(\n",
        "            include_thoughts = True,\n",
        "            thinking_level=types.ThinkingLevel.HIGH  # Dynamic thinking for high reasoning tasks\n",
        "        )\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "O-3o8P0Fi0sb"
      },
      "id": "O-3o8P0Fi0sb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show thoughts and response"
      ],
      "metadata": {
        "id": "NF4RzZECjNEZ"
      },
      "id": "NF4RzZECjNEZ"
    },
    {
      "cell_type": "code",
      "source": [
        "for part in reasoning_response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "qF48FmTMjGdD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "f269bec1-3511-4c58-90c9-521fce316f86"
      },
      "id": "qF48FmTMjGdD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         **Refining The Recommendation**\n\n\\n\\n\n\nI've clarified the constraints and critical path. My analysis highlighted the 1:30 PM slide deadline as the key driver. The initial thought was to use the 1:30 PM to 2:00 PM window. However, the \"running behind\" note and the urgent \"finish slides!!!\" message solidified that it's safer to postpone these tasks until *after* the slides are done at 1:30 PM. The final answer: 1:30 PM, immediately after the slide deadline. The response now clearly reflects this.\n\n\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         Based on the schedule and notes in the image, the latest possible time (and arguably the *safest* time) to address these interruptions is **1:30 PM**.\n\nHere is the breakdown of the timeline:\n\n1.  **The Priority:** You have a hard deadline noted as **\"Slides by 1:30 pm\"**. The note in the bottom right corner says **\"running behind,\"** which suggests you cannot afford to stop working on the slides before they are finished.\n2.  **The Window:** Once you finish the slides at **1:30 PM**, you have a 30-minute gap before your next hard commitment.\n3.  **The Hard Stop:** Your **Design Review** begins promptly at **2:00 PM**.\n\nTherefore, you have the window between **1:30 PM and 2:00 PM** to handle the red-ink \"Project team\" request and the blue-ink \"Customer question.\"\n        "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_generation = client.models.generate_content(\n",
        "    model=\"gemini-3-pro-image-preview\",\n",
        "    contents=f\"Generate an infographic of the daily schedule: {reasoning_response.text}.\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        image_config=types.ImageConfig(\n",
        "            aspect_ratio=\"16:9\",\n",
        "            image_size=\"4K\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "image_parts = [part for part in image_generation.parts if part.inline_data]\n",
        "\n",
        "if image_parts:\n",
        "    image = image_parts[0].as_image()\n",
        "    image.save('infographic_reason_1.png')\n",
        "    image.show()"
      ],
      "metadata": {
        "id": "lE7Enoj8jBID"
      },
      "id": "lE7Enoj8jBID",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "gemini_3_usecase"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}